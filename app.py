import streamlit as st
import torch
from PIL import Image
import io
from transformers import AutoProcessor
from longcat_image.models import LongCatImageTransformer2DModel
from longcat_image.pipelines import LongCatImagePipeline, LongCatImageEditPipeline

st.set_page_config(
    page_title="LongCat-Image ç½‘é¡µç•Œé¢",
    page_icon="ğŸ±",
    layout="wide"
)

@st.cache_resource
def load_t2i_model(checkpoint_dir, use_cpu_offload=True):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    text_processor = AutoProcessor.from_pretrained(checkpoint_dir, subfolder='tokenizer')
    transformer = LongCatImageTransformer2DModel.from_pretrained(
        checkpoint_dir,
        subfolder='transformer',
        torch_dtype=torch.bfloat16,
        use_safetensors=True
    ).to(device)

    pipe = LongCatImagePipeline.from_pretrained(
        checkpoint_dir,
        transformer=transformer,
        text_processor=text_processor,
        torch_dtype=torch.bfloat16
    )

    if use_cpu_offload:
        pipe.enable_model_cpu_offload()
    else:
        pipe.to(device, torch.bfloat16)

    return pipe

@st.cache_resource
def load_edit_model(checkpoint_dir, use_cpu_offload=True):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    text_processor = AutoProcessor.from_pretrained(checkpoint_dir, subfolder='tokenizer')
    transformer = LongCatImageTransformer2DModel.from_pretrained(
        checkpoint_dir,
        subfolder='transformer',
        torch_dtype=torch.bfloat16,
        use_safetensors=True
    ).to(device)

    pipe = LongCatImageEditPipeline.from_pretrained(
        checkpoint_dir,
        transformer=transformer,
        text_processor=text_processor,
        torch_dtype=torch.bfloat16
    )

    if use_cpu_offload:
        pipe.enable_model_cpu_offload()
    else:
        pipe.to(device, torch.bfloat16)

    return pipe

def main():
    st.title("ğŸ± LongCat-Image ç½‘é¡µç•Œé¢")
    st.markdown("### ä¸­è‹±åŒè¯­æ–‡ç”Ÿå›¾ä¸å›¾åƒç¼–è¾‘")

    st.sidebar.header("æ¨¡å‹é…ç½®")

    t2i_checkpoint = st.sidebar.text_input(
        "æ–‡ç”Ÿå›¾æ¨¡å‹è·¯å¾„",
        value="./weights/LongCat-Image",
        help="LongCat-Image æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•è·¯å¾„"
    )

    edit_checkpoint = st.sidebar.text_input(
        "å›¾åƒç¼–è¾‘æ¨¡å‹è·¯å¾„",
        value="./weights/LongCat-Image-Edit",
        help="LongCat-Image-Edit æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•è·¯å¾„"
    )

    use_cpu_offload = st.sidebar.checkbox(
        "å¯ç”¨ CPU å¸è½½",
        value=True,
        help="å¯ç”¨å¯èŠ‚çœæ˜¾å­˜(é€Ÿåº¦è¾ƒæ…¢ä½†é¿å…æ˜¾å­˜æº¢å‡º)ã€‚åœ¨é«˜æ˜¾å­˜è®¾å¤‡ä¸Šç¦ç”¨å¯è·å¾—æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚"
    )

    tab1, tab2, tab3 = st.tabs(["ğŸ“ æ–‡ç”Ÿå›¾", "âœï¸ å›¾åƒç¼–è¾‘", "â„¹ï¸ å…³äº"])

    with tab1:
        st.header("æ–‡ç”Ÿå›¾ç”Ÿæˆ")
        st.info("âš ï¸ **æ–‡å­—æ¸²æŸ“ç‰¹æ®Šå¤„ç†**: å½“ç”ŸæˆåŒ…å«æ–‡å­—çš„å›¾åƒæ—¶,è¯·å°†ç›®æ ‡æ–‡å­—ç”¨å¼•å·(\"\")æ‹¬èµ·æ¥ä»¥è·å¾—æ›´å¥½çš„è´¨é‡ã€‚")

        col1, col2 = st.columns([1, 1])

        with col1:
            prompt = st.text_area(
                "æç¤ºè¯",
                value='ä¸€ä¸ªå¹´è½»çš„äºšè£”å¥³æ€§,èº«ç©¿é»„è‰²é’ˆç»‡è¡«,æ­é…ç™½è‰²é¡¹é“¾ã€‚å¥¹çš„åŒæ‰‹æ”¾åœ¨è†ç›–ä¸Š,è¡¨æƒ…æ¬é™ã€‚èƒŒæ™¯æ˜¯ä¸€å µç²—ç³™çš„ç –å¢™,åˆåçš„é˜³å…‰æ¸©æš–åœ°æ´’åœ¨å¥¹èº«ä¸Š,è¥é€ å‡ºä¸€ç§å®é™è€Œæ¸©é¦¨çš„æ°›å›´ã€‚',
                height=150,
                help="è¾“å…¥ä¸­æ–‡æˆ–è‹±æ–‡çš„å›¾åƒç”Ÿæˆæç¤ºè¯"
            )

            negative_prompt = st.text_area(
                "è´Ÿé¢æç¤ºè¯(å¯é€‰)",
                value='',
                height=80,
                help="æè¿°æ‚¨ä¸å¸Œæœ›åœ¨å›¾åƒä¸­å‡ºç°çš„å†…å®¹"
            )

            col1_1, col1_2 = st.columns(2)
            with col1_1:
                width = st.slider("å®½åº¦", min_value=512, max_value=2048, value=1344, step=64)
                guidance_scale = st.slider("å¼•å¯¼å¼ºåº¦", min_value=1.0, max_value=10.0, value=4.5, step=0.1)
                enable_cfg_renorm = st.checkbox("å¯ç”¨ CFG é‡å½’ä¸€åŒ–", value=True)

            with col1_2:
                height = st.slider("é«˜åº¦", min_value=512, max_value=2048, value=768, step=64)
                num_inference_steps = st.slider("æ¨ç†æ­¥æ•°", min_value=10, max_value=100, value=50, step=5)
                enable_prompt_rewrite = st.checkbox("å¯ç”¨æç¤ºè¯é‡å†™", value=True, help="ä½¿ç”¨å†…ç½®çš„æ–‡æœ¬ç¼–ç å™¨ä½œä¸ºæç¤ºè¯æ”¹å†™å™¨")

            num_images = st.number_input("å›¾åƒæ•°é‡", min_value=1, max_value=4, value=1)
            seed = st.number_input("éšæœºç§å­", min_value=-1, max_value=999999, value=43, help="ä½¿ç”¨ -1 è¡¨ç¤ºéšæœºç§å­")

            generate_button = st.button("ğŸ¨ ç”Ÿæˆå›¾åƒ", type="primary", use_container_width=True)

        with col2:
            if generate_button:
                try:
                    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
                        pipe = load_t2i_model(t2i_checkpoint, use_cpu_offload)

                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾åƒ... è¿™å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´ã€‚"):
                        generator = torch.Generator("cpu").manual_seed(seed) if seed >= 0 else None

                        result = pipe(
                            prompt,
                            negative_prompt=negative_prompt if negative_prompt else '',
                            height=height,
                            width=width,
                            guidance_scale=guidance_scale,
                            num_inference_steps=num_inference_steps,
                            num_images_per_prompt=num_images,
                            generator=generator,
                            enable_cfg_renorm=enable_cfg_renorm,
                            enable_prompt_rewrite=enable_prompt_rewrite
                        )

                        images = result.images

                        st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(images)} å¼ å›¾åƒ!")

                        for idx, image in enumerate(images):
                            st.image(image, caption=f"ç”Ÿæˆå›¾åƒ {idx + 1}", use_container_width=True)

                            buf = io.BytesIO()
                            image.save(buf, format='PNG')
                            buf.seek(0)

                            st.download_button(
                                label=f"â¬‡ï¸ ä¸‹è½½å›¾åƒ {idx + 1}",
                                data=buf,
                                file_name=f"longcat_t2i_{idx + 1}.png",
                                mime="image/png",
                                use_container_width=True
                            )

                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {str(e)}")
                    st.exception(e)
            else:
                st.info("ğŸ‘ˆ é…ç½®å‚æ•°åç‚¹å‡»'ç”Ÿæˆå›¾åƒ'å¼€å§‹")

    with tab2:
        st.header("å›¾åƒç¼–è¾‘")
        st.info("âš ï¸ **æ–‡å­—æ¸²æŸ“ç‰¹æ®Šå¤„ç†**: å½“ç¼–è¾‘åŒ…å«æ–‡å­—çš„å›¾åƒæ—¶,è¯·å°†ç›®æ ‡æ–‡å­—ç”¨å¼•å·(\"\")æ‹¬èµ·æ¥ä»¥è·å¾—æ›´å¥½çš„è´¨é‡ã€‚")

        col1, col2 = st.columns([1, 1])

        with col1:
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ å›¾åƒ",
                type=['png', 'jpg', 'jpeg'],
                help="ä¸Šä¼ è¦ç¼–è¾‘çš„å›¾åƒ"
            )

            if uploaded_file is not None:
                input_image = Image.open(uploaded_file).convert('RGB')
                st.image(input_image, caption="è¾“å…¥å›¾åƒ", use_container_width=True)

            edit_prompt = st.text_area(
                "ç¼–è¾‘æŒ‡ä»¤",
                value='å°†çŒ«å˜æˆç‹—',
                height=100,
                help="æè¿°æ‚¨æƒ³å¦‚ä½•ç¼–è¾‘å›¾åƒ"
            )

            edit_negative_prompt = st.text_area(
                "è´Ÿé¢æç¤ºè¯(å¯é€‰)",
                value='',
                height=80,
                help="æè¿°æ‚¨ä¸å¸Œæœ›åœ¨ç¼–è¾‘åçš„å›¾åƒä¸­å‡ºç°çš„å†…å®¹"
            )

            col2_1, col2_2 = st.columns(2)
            with col2_1:
                edit_guidance_scale = st.slider("å¼•å¯¼å¼ºåº¦", min_value=1.0, max_value=10.0, value=4.5, step=0.1, key="edit_guidance")
                edit_num_images = st.number_input("å›¾åƒæ•°é‡", min_value=1, max_value=4, value=1, key="edit_num_images")

            with col2_2:
                edit_num_inference_steps = st.slider("æ¨ç†æ­¥æ•°", min_value=10, max_value=100, value=50, step=5, key="edit_steps")
                edit_seed = st.number_input("éšæœºç§å­", min_value=-1, max_value=999999, value=43, help="ä½¿ç”¨ -1 è¡¨ç¤ºéšæœºç§å­", key="edit_seed")

            edit_button = st.button("âœï¸ ç¼–è¾‘å›¾åƒ", type="primary", use_container_width=True, disabled=(uploaded_file is None))

        with col2:
            if edit_button and uploaded_file is not None:
                try:
                    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
                        edit_pipe = load_edit_model(edit_checkpoint, use_cpu_offload)

                    with st.spinner("æ­£åœ¨ç¼–è¾‘å›¾åƒ... è¿™å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´ã€‚"):
                        edit_generator = torch.Generator("cpu").manual_seed(edit_seed) if edit_seed >= 0 else None

                        result = edit_pipe(
                            input_image,
                            edit_prompt,
                            negative_prompt=edit_negative_prompt if edit_negative_prompt else '',
                            guidance_scale=edit_guidance_scale,
                            num_inference_steps=edit_num_inference_steps,
                            num_images_per_prompt=edit_num_images,
                            generator=edit_generator
                        )

                        images = result.images

                        st.success(f"âœ… æˆåŠŸç¼–è¾‘ {len(images)} å¼ å›¾åƒ!")

                        for idx, image in enumerate(images):
                            st.image(image, caption=f"ç¼–è¾‘åå›¾åƒ {idx + 1}", use_container_width=True)

                            buf = io.BytesIO()
                            image.save(buf, format='PNG')
                            buf.seek(0)

                            st.download_button(
                                label=f"â¬‡ï¸ ä¸‹è½½ç¼–è¾‘åå›¾åƒ {idx + 1}",
                                data=buf,
                                file_name=f"longcat_edit_{idx + 1}.png",
                                mime="image/png",
                                use_container_width=True
                            )

                except Exception as e:
                    st.error(f"âŒ ç¼–è¾‘å›¾åƒæ—¶å‡ºé”™: {str(e)}")
                    st.exception(e)
            else:
                st.info("ğŸ‘ˆ ä¸Šä¼ å›¾åƒå¹¶é…ç½®å‚æ•°å¼€å§‹ç¼–è¾‘")

    with tab3:
        st.header("å…³äº LongCat-Image")

        st.markdown("""
        ### ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

        - **å“è¶Šçš„æ•ˆç‡ä¸æ€§èƒ½**: ä»…ç”¨ **6B å‚æ•°**, LongCat-Image åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†è®¸å¤šä½“ç§¯æ•°å€çš„å¼€æºæ¨¡å‹ã€‚

        - **å‡ºè‰²çš„ç¼–è¾‘æ€§èƒ½**: LongCat-Image-Edit æ¨¡å‹åœ¨å¼€æºæ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½,å…·æœ‰å“è¶Šçš„è§†è§‰ä¸€è‡´æ€§ã€‚

        - **å¼ºå¤§çš„ä¸­æ–‡æ–‡å­—æ¸²æŸ“**: åœ¨å¸¸è§ä¸­æ–‡å­—ç¬¦æ¸²æŸ“æ–¹é¢,ç›¸æ¯”ç°æœ‰ SOTA å¼€æºæ¨¡å‹è¡¨ç°å‡ºå“è¶Šçš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

        - **å‡ºè‰²çš„ç…§ç‰‡çœŸå®æ„Ÿ**: é€šè¿‡åˆ›æ–°çš„æ•°æ®ç­–ç•¥å’Œè®­ç»ƒæ¡†æ¶, LongCat-Image åœ¨ç”Ÿæˆå›¾åƒä¸­å®ç°äº†å‡ºè‰²çš„ç…§ç‰‡çœŸå®æ„Ÿã€‚

        - **å…¨é¢çš„å¼€æºç”Ÿæ€ç³»ç»Ÿ**: ä»ä¸­é—´æ£€æŸ¥ç‚¹åˆ°å®Œæ•´è®­ç»ƒä»£ç çš„å®Œæ•´å·¥å…·é“¾ã€‚

        ### ğŸ“š èµ„æº

        - [GitHub ä»“åº“](https://github.com/meituan-longcat/LongCat-Image)
        - [arXiv æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2512.07584)
        - [åœ¨çº¿æ¼”ç¤º](https://longcat.ai/)
        - [Hugging Face - LongCat-Image](https://huggingface.co/meituan-longcat/LongCat-Image)
        - [Hugging Face - LongCat-Image-Edit](https://huggingface.co/meituan-longcat/LongCat-Image-Edit)

        ### ğŸ“ å¼•ç”¨

        ```bibtex
        @article{LongCat-Image,
              title={LongCat-Image Technical Report},
              author={Meituan LongCat Team and  Hanghang Ma and Haoxian Tan and Jiale Huang and Junqiang Wu and Jun-Yan He and Lishuai Gao and Songlin Xiao and Xiaoming Wei and Xiaoqi Ma and Xunliang Cai and Yayong Guan and Jie Hu},
              journal={arXiv preprint arXiv:2512.07584},
              year={2025}
        }
        ```

        ### ğŸ“§ è”ç³»æ–¹å¼

        - é‚®ç®±: longcat-team@meituan.com
        - Twitter: [@Meituan_LongCat](https://x.com/Meituan_LongCat)

        ### âš–ï¸ è®¸å¯è¯

        LongCat-Image é‡‡ç”¨ Apache 2.0 è®¸å¯è¯ã€‚

        ---

        ç”±ç¾å›¢ LongCat å›¢é˜Ÿç”¨ â¤ï¸ æ„å»º
        """)

if __name__ == "__main__":
    main()
